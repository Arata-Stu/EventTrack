{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import torch\n",
    "import lightning as pl\n",
    "from einops import rearrange, reduce\n",
    "\n",
    "from utils.padding import InputPadderFromShape\n",
    "from data.utils.types import DatasetMode, DataType\n",
    "from data.genx_utils.labels import ObjectLabels\n",
    "from modules.utils.detection import RNNStates\n",
    "from models.layers.yolox.utils.boxes import postprocess, postprocess_with_motion\n",
    "\n",
    "# —————————————————————————————————————————\n",
    "# トラッカー実装\n",
    "# —————————————————————————————————————————\n",
    "class TrackedObject:\n",
    "    def __init__(self, object_id, cx, cy, w, h, dx=0, dy=0):\n",
    "        self.object_id = object_id\n",
    "        self.cx = cx\n",
    "        self.cy = cy\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "        self.dx = dx\n",
    "        self.dy = dy\n",
    "        self.lost_frames = 0\n",
    "    \n",
    "    def predict_next_position(self):\n",
    "        self.cx += self.dx\n",
    "        self.cy += self.dy\n",
    "        return self.cx, self.cy\n",
    "\n",
    "class ObjectTracker:\n",
    "    def __init__(self, max_lost=5, iou_threshold=0.3):\n",
    "        self.objects = {}\n",
    "        self.next_id = 0\n",
    "        self.max_lost = max_lost\n",
    "        self.iou_threshold = iou_threshold\n",
    "    \n",
    "    def iou(self, boxA, boxB):\n",
    "        xA = max(boxA[0] - boxA[2]/2, boxB[0] - boxB[2]/2)\n",
    "        yA = max(boxA[1] - boxA[3]/2, boxB[1] - boxB[3]/2)\n",
    "        xB = min(boxA[0] + boxA[2]/2, boxB[0] + boxB[2]/2)\n",
    "        yB = min(boxA[1] + boxA[3]/2, boxB[1] + boxB[3]/2)\n",
    "\n",
    "        interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "        boxAArea = boxA[2] * boxA[3]\n",
    "        boxBArea = boxB[2] * boxB[3]\n",
    "        return interArea / float(boxAArea + boxBArea - interArea + 1e-6)\n",
    "    \n",
    "    def update(self, detections):\n",
    "        assigned = set()\n",
    "        # 既存オブジェクトを更新\n",
    "        for oid, obj in list(self.objects.items()):\n",
    "            obj.predict_next_position()\n",
    "            best_iou = 0\n",
    "            best_det = None\n",
    "            for det in detections:\n",
    "                if det in assigned:\n",
    "                    continue\n",
    "                i = self.iou((obj.cx, obj.cy, obj.w, obj.h), det)\n",
    "                if i > best_iou and i > self.iou_threshold:\n",
    "                    best_iou = i\n",
    "                    best_det = det\n",
    "            if best_det is not None:\n",
    "                obj.cx, obj.cy, obj.w, obj.h = best_det\n",
    "                assigned.add(best_det)\n",
    "                obj.lost_frames = 0\n",
    "            else:\n",
    "                obj.lost_frames += 1\n",
    "            if obj.lost_frames > self.max_lost:\n",
    "                del self.objects[oid]\n",
    "        \n",
    "        # 新規オブジェクトを追加\n",
    "        for det in detections:\n",
    "            if det not in assigned:\n",
    "                self.objects[self.next_id] = TrackedObject(self.next_id, *det)\n",
    "                self.next_id += 1\n",
    "    \n",
    "    def get_tracked_objects(self):\n",
    "        # (id, cx, cy, w, h) のリストを返す\n",
    "        return [(o.object_id, o.cx, o.cy, o.w, o.h) for o in self.objects.values()]\n",
    "\n",
    "# —————————————————————————————————————————\n",
    "# 推論ループ\n",
    "# —————————————————————————————————————————\n",
    "dataset2size = {\n",
    "    \"gen1\": (304, 240),\n",
    "    \"gen4\": (640, 360),\n",
    "    \"VGA\":  (640, 480),\n",
    "}\n",
    "dataset2labelmap = {\n",
    "    \"gen1\": (\"car\", \"pedestrian\"),\n",
    "    \"gen4\": (\"pedestrian\",\"two wheeler\",\"car\"),\n",
    "    \"VGA\":  (\"pedestrian\",\"two wheeler\",\"car\"),\n",
    "}\n",
    "\n",
    "def inference(\n",
    "    data: pl.LightningDataModule,\n",
    "    model: pl.LightningModule,\n",
    "    ckpt_path: str,\n",
    "    show_gt: bool,\n",
    "    show_pred: bool,\n",
    "    output_path: str,\n",
    "    fps: int,\n",
    "    num_sequence: int,\n",
    "    dataset_mode: DatasetMode\n",
    "):\n",
    "    # 動画書き出し準備\n",
    "    size = dataset2size[data.dataset_name]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video_writer = cv2.VideoWriter(output_path, fourcc, fps, size)\n",
    "    \n",
    "    # DataModule モード切り替え\n",
    "    if dataset_mode == \"train\":\n",
    "        data.setup('fit')\n",
    "        loader = data.train_dataloader()\n",
    "        model.setup(\"fit\")\n",
    "    elif dataset_mode == \"val\":\n",
    "        data.setup('validate')\n",
    "        loader = data.val_dataloader()\n",
    "        model.setup(\"validate\")\n",
    "    elif dataset_mode == \"test\":\n",
    "        data.setup('test')\n",
    "        loader = data.test_dataloader()\n",
    "        model.setup(\"test\")\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid mode: {dataset_mode}\")\n",
    "    \n",
    "    num_classes = len(dataset2labelmap[data.dataset_name])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 推論用準備\n",
    "    if show_pred:\n",
    "        model.eval().to(device)\n",
    "        rnn_state = RNNStates()\n",
    "        padder = InputPadderFromShape(model.in_res_hw)\n",
    "    \n",
    "    # チェックポイント読み込み\n",
    "    if ckpt_path:\n",
    "        ckpt = torch.load(ckpt_path, map_location=device)\n",
    "        model.load_state_dict(ckpt['state_dict'])\n",
    "    \n",
    "    sequence_count = 0\n",
    "    for batch in tqdm(loader):\n",
    "        ev_repr = batch[\"data\"][DataType.EV_REPR]\n",
    "        labels  = batch[\"data\"][DataType.OBJLABELS_SEQ]\n",
    "        is_first = batch[\"data\"][DataType.IS_FIRST_SAMPLE]\n",
    "        \n",
    "        # 新シーケンス開始ならトラッカーをリセット\n",
    "        if is_first.any():\n",
    "            sequence_count += 1\n",
    "            if sequence_count > num_sequence:\n",
    "                break\n",
    "            tracker = ObjectTracker(max_lost=5, iou_threshold=0.3)\n",
    "            prev_states = None\n",
    "        \n",
    "        seq_len = len(ev_repr)\n",
    "        for t in range(seq_len):\n",
    "            # 入力テンソル準備\n",
    "            ev = ev_repr[t].to(torch.float32).to(device)\n",
    "            \n",
    "            # ——— Ground Truth（必要なら）\n",
    "            if show_gt:\n",
    "                cur_labels, valid_idx = labels[t].get_valid_labels_and_batch_indices()\n",
    "                if len(cur_labels) > 0:\n",
    "                    labels_yolox = ObjectLabels.get_labels_as_batched_tensor(\n",
    "                        obj_label_list=cur_labels, format_=model.mdl_config.label.format\n",
    "                    )\n",
    "                else:\n",
    "                    labels_yolox = None\n",
    "            \n",
    "            # ——— 推論\n",
    "            if show_pred:\n",
    "                ev_padded = padder.pad_tensor_ev_repr(ev)\n",
    "                if model.mdl.model_type == 'DNN':\n",
    "                    preds, _ = model.forward(event_tensor=ev_padded)\n",
    "                else:  # RNN\n",
    "                    if prev_states is None:\n",
    "                        rnn_state.reset(worker_id=0, indices_or_bool_tensor=is_first)\n",
    "                        prev_states = rnn_state.get_states(worker_id=0)\n",
    "                    preds, _, states = model.forward(\n",
    "                        event_tensor=ev_padded, previous_states=prev_states\n",
    "                    )\n",
    "                    prev_states = states\n",
    "                    rnn_state.save_states_and_detach(worker_id=0, states=states)\n",
    "                \n",
    "                fmt = model.mdl_config.label.format\n",
    "                if fmt == 'yolox':\n",
    "                    dets = postprocess(predictions=preds, num_classes=num_classes,\n",
    "                                       conf_thre=0.1, nms_thre=0.45)\n",
    "                else:\n",
    "                    dets = postprocess_with_motion(prediction=preds, num_classes=num_classes,\n",
    "                                                   conf_thre=0.1, nms_thre=0.45)\n",
    "                \n",
    "                # バウンディングボックスを (cx,cy,w,h) リストへ変換\n",
    "                det_list = []\n",
    "                for x1, y1, x2, y2, conf, cls in dets[0].cpu().numpy():\n",
    "                    cx = (x1 + x2) / 2\n",
    "                    cy = (y1 + y2) / 2\n",
    "                    w  =  x2 - x1\n",
    "                    h  =  y2 - y1\n",
    "                    det_list.append((cx, cy, w, h))\n",
    "                \n",
    "                # トラッカー更新・取得\n",
    "                tracker.update(det_list)\n",
    "                tracked_objs = tracker.get_tracked_objects()\n",
    "                # tracked_objs: [(id, cx, cy, w, h), ...]\n",
    "            \n",
    "            # ——— フレームごとの描画はここで行う or バッファに貯める\n",
    "            # visualize(video_writer, ev, labels_yolox, tracked_objs, data.dataset_name)\n",
    "        \n",
    "        # シーケンス終了後の書き出し（必要なら）\n",
    "    \n",
    "    video_writer.release()\n",
    "    print(\"Inference done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "from modules.utils.fetch import fetch_data_module, fetch_model_module\n",
    "from config.modifier import dynamically_modify_train_config\n",
    "\n",
    "\n",
    "yaml_path = \"sample.config.yaml\"\n",
    "config = OmegaConf.load(yaml_path)\n",
    "dynamically_modify_train_config(config)\n",
    "## データセットの読み込み\n",
    "data = fetch_data_module(config=config)\n",
    "## モデルの読み込み\n",
    "module = fetch_model_module(config=config)\n",
    "\n",
    "ckpt_path = \"path/to/your/checkpoint.ckpt\"\n",
    "\n",
    "inference(data=data,\n",
    "          model=module,\n",
    "          ckpt_path=ckpt_path,\n",
    "          show_gt=False,\n",
    "          show_pred=True,\n",
    "          output_path=\"./output.mp4\",\n",
    "          fps=10,\n",
    "          num_sequence=1,\n",
    "          dataset_mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
